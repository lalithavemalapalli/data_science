{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Advanced Assignment: Getting Started with Pandas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Assignment 1: Complex DataFrame Manipulation** (20 points)\n",
        "**Objective**: Practice advanced DataFrame creation, manipulation, and indexing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Task**:\n",
        "   - Create a DataFrame from the following multi-level dictionary representing students' scores:\n",
        "     ```python\n",
        "     data = {\n",
        "         'Grade 9': {\n",
        "             'Math': [78, 88, 95, 67],\n",
        "             'English': [82, 79, 88, 91],\n",
        "         },\n",
        "         'Grade 10': {\n",
        "             'Math': [81, 85, 79, 92],\n",
        "             'English': [84, 90, 73, 87],\n",
        "         }\n",
        "     }\n",
        "     ```\n",
        "   - Set the column index to reflect both `Grade` and `Subject`, with the rows representing individual students.\n",
        "   - Perform the following operations:\n",
        "     - Select all the `Math` scores for `Grade 10`.\n",
        "     - Calculate the average `English` score across both grades."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "         'Grade 9': {\n",
        "             'Math': [78, 88, 95, 67],\n",
        "             'English': [82, 79, 88, 91],\n",
        "         },\n",
        "         'Grade 10': {\n",
        "             'Math': [81, 85, 79, 92],\n",
        "             'English': [84, 90, 73, 87],\n",
        "         }\n",
        "     }\n",
        "\n",
        "df=pd.DataFrame({(grade,subjects):scores for grade,subject in data.items()for subjects,scores in subject.items()})\n",
        "print(df)\n",
        "\n",
        "math_scoresof_grade10 = df[('Grade 10','Math')]\n",
        "print(\"\\nMath scores for Grade 10:\")\n",
        "print(math_scoresof_grade10)\n",
        "\n",
        "english_avg = df[[('Grade 9', 'English'), ('Grade 10', 'English')]].mean()\n",
        "print(\"\\nAverage English score across both grades:\")\n",
        "print(english_avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Assignment 2: Advanced Indexing and Filtering** (20 points)\n",
        "**Objective**: Practice complex indexing and filtering on a DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Task**:\n",
        "   - Create a DataFrame representing the sales of various products across different regions:\n",
        "     ```python\n",
        "     data = {\n",
        "         'Product': ['A', 'B', 'C', 'D'],\n",
        "         'Region': ['North', 'South', 'East', 'West'],\n",
        "         'Sales_Q1': [120, 150, 200, 130],\n",
        "         'Sales_Q2': [180, 140, 170, 160]\n",
        "     }\n",
        "     ```\n",
        "   - Set `Product` as the index of the DataFrame.\n",
        "   - Perform the following operations:\n",
        "     - Select only those products where `Sales_Q2` is greater than `Sales_Q1`.\n",
        "     - Filter and display rows where `Sales_Q1` or `Sales_Q2` exceeds 160.\n",
        "     - Replace all sales values greater than 170 with the value `170`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "         'Product': ['A', 'B', 'C', 'D'],\n",
        "         'Region': ['North', 'South', 'East', 'West'],\n",
        "         'Sales_Q1': [120, 150, 200, 130],\n",
        "         'Sales_Q2': [180, 140, 170, 160]\n",
        "     }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data).set_index('Product')\n",
        "print(df)\n",
        "\n",
        "sales_q2_greater_q1 = df[df['Sales_Q2'] > df['Sales_Q1']]\n",
        "print(\"\\nProducts where Sales_Q2 is greater than Sales_Q1:\")\n",
        "print(sales_q2_greater_q1)\n",
        "\n",
        "sales_exceeds_160 = df[(df['Sales_Q1'] > 160) | (df['Sales_Q2'] > 160)]\n",
        "print(\"\\nRows where Sales_Q1 or Sales_Q2 exceeds 160:\")\n",
        "print(sales_exceeds_160)\n",
        "\n",
        "df[['Sales_Q1', 'Sales_Q2']] = df[['Sales_Q1', 'Sales_Q2']].applymap(lambda x: 170 if x > 170 else x)\n",
        "print(\"\\nDataFrame with sales values capped at 170:\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Assignment 3: Grouping with Multiple Aggregations** (20 points)\n",
        "**Objective**: Perform complex groupby operations with multiple aggregation functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Task**:\n",
        "   - Create a DataFrame with the following data on employees, their department, and monthly salary:\n",
        "     ```python\n",
        "     data = {\n",
        "         'Employee': ['John', 'Jane', 'Tom', 'Lucy', 'Max', 'Anna'],\n",
        "         'Department': ['HR', 'Finance', 'HR', 'Finance', 'Sales', 'Sales'],\n",
        "         'Salary': [3000, 4000, 3500, 4200, 3700, 3800],\n",
        "         'Experience': [2, 5, 3, 4, 2, 6]\n",
        "     }\n",
        "     ```\n",
        "   - Group the data by `Department` and calculate the following for each department:\n",
        "     - The total salary.\n",
        "     - The average experience.\n",
        "   - Further, apply multiple aggregation functions to the `Salary` column: find the minimum, maximum, and mean salary for each department."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "         'Employee': ['John', 'Jane', 'Tom', 'Lucy', 'Max', 'Anna'],\n",
        "         'Department': ['HR', 'Finance', 'HR', 'Finance', 'Sales', 'Sales'],\n",
        "         'Salary': [3000, 4000, 3500, 4200, 3700, 3800],\n",
        "         'Experience': [2, 5, 3, 4, 2, 6]\n",
        "     }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "grouped = df.groupby('Department')\n",
        "\n",
        "department_totals = grouped.agg(\n",
        "    Total_Salary=('Salary', 'sum'),\n",
        "    Avg_Experience=('Experience', 'mean')\n",
        ")\n",
        "\n",
        "salary_stats = grouped['Salary'].agg(['min', 'max', 'mean'])\n",
        "print(\"Total Salary and Average Experience by Department:\")\n",
        "print(department_totals)\n",
        "print(\"\\nSalary Statistics by Department:\")\n",
        "print(salary_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Assignment 4: Complex Merging and Joining** (15 points)\n",
        "**Objective**: Use advanced merging techniques to combine multiple DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "plt.hist(xyz_avg[:,0])\n",
        "plt.title('Average $x(t)$');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Task**:\n",
        "   - Create two DataFrames:\n",
        "     - One representing customer details:\n",
        "       ```python\n",
        "       customers = {\n",
        "           'CustomerID': [1, 2, 3, 4],\n",
        "           'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "           'Country': ['USA', 'Canada', 'USA', 'Mexico']\n",
        "       }\n",
        "       ```\n",
        "     - Another representing order details:\n",
        "       ```python\n",
        "       orders = {\n",
        "           'OrderID': [101, 102, 103, 104],\n",
        "           'CustomerID': [1, 2, 2, 3],\n",
        "           'Amount': [250, 100, 200, 150]\n",
        "       }\n",
        "       ```\n",
        "   - Merge the two DataFrames on `CustomerID` and perform the following:\n",
        "     - Display all customers, even if they donâ€™t have any orders.\n",
        "     - Calculate the total amount spent by each customer, including those with no orders.\n",
        "     - Sort the merged DataFrame by `Amount` in descending order, placing missing values (`NaN`) at the bottom.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "customers = {\n",
        "    'CustomerID': [1, 2, 3, 4],\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Country': ['USA', 'Canada', 'USA', 'Mexico']\n",
        "}\n",
        "\n",
        "orders = {\n",
        "    'OrderID': [101, 102, 103, 104],\n",
        "    'CustomerID': [1, 2, 2, 3],\n",
        "    'Amount': [250, 100, 200, 150]\n",
        "}\n",
        "\n",
        "df_customers = pd.DataFrame(customers)\n",
        "df_orders = pd.DataFrame(orders)\n",
        "\n",
        "merged_df = pd.merge(df_customers, df_orders, on='CustomerID', how='left')\n",
        "print(\"Merged DataFrame (all customers):\")\n",
        "print(merged_df)\n",
        "\n",
        "total_amount_spent = merged_df.groupby(['CustomerID', 'Name', 'Country'])['Amount'].sum().reset_index()\n",
        "print(\"\\nTotal amount spent by each customer:\")\n",
        "print(total_amount_spent)\n",
        "\n",
        "\n",
        "sorted_df = merged_df.sort_values(by='Amount', ascending=False)\n",
        "print(\"\\nMerged DataFrame sorted by Amount:\")\n",
        "print(sorted_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Assignment 5: Advanced Pivoting and Reshaping** (15 points)\n",
        "**Objective**: Use pivoting, stacking, and unstacking techniques for reshaping data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Task**:\n",
        "   - Create a DataFrame representing temperature readings at different times across three cities:\n",
        "     ```python\n",
        "     data = {\n",
        "         'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Los Angeles', 'Chicago'],\n",
        "         'Date': ['2023-01-01', '2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-02'],\n",
        "         'Temperature': [30, 75, 25, 32, 77, 27],\n",
        "         'Time': ['Morning', 'Morning', 'Morning', 'Afternoon', 'Afternoon', 'Afternoon']\n",
        "     }\n",
        "     ```\n",
        "   - Pivot the data to create a table where the rows represent the `Date` and the columns represent the cities, with the temperature readings as the values.\n",
        "   - Stack and unstack the pivoted data to swap the hierarchy of the cities and time of the day (`Morning`, `Afternoon`).\n",
        "   - Calculate the daily average temperature for each city."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Los Angeles', 'Chicago'],\n",
        "    'Date': ['2023-01-01', '2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02', '2023-01-02'],\n",
        "    'Temperature': [30, 75, 25, 32, 77, 27],\n",
        "    'Time': ['Morning', 'Morning', 'Morning', 'Afternoon', 'Afternoon', 'Afternoon']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original DataFrame:\\n\", df)\n",
        "\n",
        "pivot_df = df.pivot(index='Date', columns='City', values='Temperature')\n",
        "print(\"\\nPivoted DataFrame:\\n\", pivot_df)\n",
        "\n",
        "stacked = df.set_index(['Date', 'Time', 'City'])\n",
        "print(\"\\nStacked  DataFrame:\\n\", stacked)\n",
        "\n",
        "x=stacked.unstack('Time')\n",
        "print(\"\\n Unstacked DataFrame:\\n\",x)\n",
        "\n",
        "daily_avg = df.groupby(['Date', 'City'])['Temperature'].mean()\n",
        "print(\"\\nDaily Average Temperature for Each City:\\n\", daily_avg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Assignment 7: Time Series Data Handling** (10 points)\n",
        "**Objective**: Practice working with time series data using pandas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Task**:\n",
        "   - Create a date range of 30 consecutive business days starting from `2023-01-01`.\n",
        "   - Create a DataFrame with random stock prices for a single company for each of these days.\n",
        "   - Calculate the rolling 7-day moving average of the stock prices.\n",
        "   - Find the day with the highest stock price and the corresponding price."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "date_range = pd.date_range(start='2023-01-01', periods=30, freq='B')\n",
        "print(\"Date Range:\\n\", date_range)\n",
        "\n",
        "np.random.seed(0)  \n",
        "stock_prices = np.random.uniform(low=100, high=200, size=30)\n",
        "df = pd.DataFrame({'Date': date_range, 'Stock Price': stock_prices})\n",
        "print(\"\\nDataFrame with Random Stock Prices:\\n\", df)\n",
        "\n",
        "df['7-Day MA'] = df['Stock Price'].rolling(window=7).mean()\n",
        "print(\"\\nDataFrame with 7-Day Moving Average:\\n\", df)\n",
        "\n",
        "max_price_row = df.loc[df['Stock Price'].idxmax()]\n",
        "print(\"\\nDay with Highest Stock Price:\\n\", max_price_row[['Date', 'Stock Price']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Assignment 8: Advanced Missing Data Handling** (10 points)\n",
        "**Objective**: Use advanced techniques to handle missing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Task**:\n",
        "   - Create a DataFrame with missing values in multiple columns:\n",
        "     ```python\n",
        "     data = {\n",
        "         'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "         'Age': [25, np.nan, 35, np.nan],\n",
        "         'Score': [85, 90, np.nan, 88]\n",
        "     }\n",
        "     ```\n",
        "   - Perform the following operations:\n",
        "     - Interpolate the missing values in the `Age` column.\n",
        "     - Fill the missing values in the `Score` column with the mean score.\n",
        "     - Drop any rows that still have missing values after the above steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [25, np.nan, 35, np.nan],\n",
        "    'Score': [85, 90, np.nan, 88]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original DataFrame with Missing Values:\\n\", df)\n",
        "\n",
        "# Step 2: Interpolate missing values in the 'Age' column\n",
        "# Interpolation fills missing values based on linear interpolation by default.\n",
        "df['Age'] = df['Age'].interpolate()\n",
        "print(\"\\nDataFrame after Interpolating 'Age':\\n\", df)\n",
        "\n",
        "# Step 3: Fill missing values in the 'Score' column with the mean score\n",
        "# `fillna(df['Score'].mean())` replaces missing values in 'Score' with the column mean.\n",
        "df['Score'] = df['Score'].fillna(df['Score'].mean())\n",
        "print(\"\\nDataFrame after Filling 'Score' with Mean:\\n\", df)\n",
        "\n",
        "# Step 4: Drop any rows that still contain missing values\n",
        "# `dropna()` removes any rows that still have NaN values after the previous steps.\n",
        "df = df.dropna()\n",
        "print(\"\\nDataFrame after Dropping Remaining Missing Values:\\n\", df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
